{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Generative AI for Developers (Python)\n",
    "`Author: Arafat Tehsin`\n",
    "\n",
    "Well, well, well, looks like we have a language polyglot in the making! And not just any polyglot, but one who's delving into the fascinating world of Azure OpenAI Service. Get ready to unleash your inner coding genius as we take you on a journey from GPT-3 Text Completions to ChatGPT (yes, we're getting chatty here!) and even sprinkle in some DALL-E for good measure. Buckle up, folks, because we're about to turn up the AI heat!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "```\n",
    "Inspired by the great designers at the Microsoft OCTO (Semantic Kernel)\n",
    "```\n",
    "### Reminder: This üìò `Polyglot` notebook needs to be run from VS Code with below pre-requisites. \n",
    "\n",
    "The following software needs to be installed on your computer:\n",
    "\n",
    "* ‚úÖ [Visual Studio Code](https://code.visualstudio.com/Download)\n",
    "* ‚úÖ [Python 3.9](https://code.visualstudio.com/docs/languages/python) \n",
    "* ‚úÖ [Polyglot Notebooks for VS Code](https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.dotnet-interactive-vscode?)\n",
    "\n",
    "When the three items above are installed, the code notebooks should be formatted nicely with code blocks that have a little ‚ñ∂Ô∏è (play) button next to them when you hover over the code. The \"Polyglot Notebooks for VS Code\" extension is what lets you run all the code snippets from within VS Code and serves as a little playground for your initial Azure OpenAI learning.\n",
    "\n",
    "Apart from installing software, you will need to have an API key to access the OpenAI models. \n",
    "\n",
    "* ‚úÖ [Azure OpenAI Service](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/quickstart?WT.mc_id=AI-MVP-5003464). Access your API key on Azure Open AI Service with [these instructions](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/reference?WT.mc_id=AI-MVP-5003464).\n",
    "\n",
    "This notebook also requires you to create a deployment of [models](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/models?WT.mc_id=AI-MVP-5003464) üß™. This means that your fresh Azure OpenAI Service won't have any model right now. \n",
    "* ‚úÖ You can create your deployments from [these docs](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal&WT.mc_id=AI-MVP-5003464). The suggestion is to have below deployments:\n",
    "\n",
    "    - `text-davinci-003` - davinci\n",
    "    - `gpt-35-turbo` - ChatGPT-Business\n",
    "    -  `gpt-4`- GPT-4\n",
    "\n",
    "\n",
    "\n",
    "### üå± Environment Variables\n",
    "\n",
    "Once you get the key and enpoint, you may want to setup from command line or the shiny [Windows Terminal](https://aka.ms/windowsterminal)\n",
    "\n",
    "* `setx AZUREOPENAI_KEY \"your_key_here\"`\n",
    "* `setx AZUREOPENAI_ENDPOINT \"your_enpoint_here\"`\n",
    "\n",
    "Or if you want to use OpenAI\n",
    "\n",
    "* `setx OPENAI_KEY \"your key here\"`\n",
    "\n",
    "#### üìò After you have achieved all the üëÜ prerequisites, open the notebooks in this repo from within Visual Studio Code and you are ready to to go!\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's try this out\n",
    "\n",
    "üëã In the event that you hit \"play\" below on the code block and it asks you to:\n",
    " \n",
    "```\n",
    "Select kernel for <filename>\n",
    "----\n",
    "Python 3.9.x üëà\n",
    "Select Another Kernel...\n",
    "----\n",
    "```\n",
    "\n",
    "Choose `Python 3.9.x` and you're good to go. That selection lets you magically run the Generative AI notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Microphone test. Check one. Two. Three.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a üî• Python kernel ready for you to load the Azure OpenAI Service package\n",
    "\n",
    "This will create a client so you don't have to initialise it again. You can read more about the [Azure OpenAI Library](https://pypi.org/project/openai/) here.\n",
    "\n",
    "### ‚ö†Ô∏è Important  \n",
    "- If you are using OpenAI APIs then you do not need specify `api_base`, `api_type` or `even api_version`\n",
    "- If you are using Azure OpenAI then you need to replace it with the correct deployment / models names which you have used in your Azure AI Studio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import openai\n",
    "\n",
    "openai.api_type = 'openai' # 'openai' or 'azure'\n",
    "\n",
    "if openai.api_type == \"openai\":\n",
    "    openai.api_key = \"\" # your key here\n",
    "    davinci = \"davinci\"\n",
    "    chatgpt = \"gpt-3.5-turbo\"\n",
    "    gpt4 = \"gpt-4\"\n",
    "else:\n",
    "    openai.api_key = \"\" # your key here\n",
    "    davinci = \"davinci\"\n",
    "    chatgpt = \"ChatGPT-Business\"\n",
    "    gpt4 = \"GPT-4\"\n",
    "    openai.api_base = os.getenv(\"AZUREOPENAI_ENDPOINT\")\n",
    "    openai.api_version = '2023-05-15'  # this may change in the future"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Note: you may need to restart the kernel to use updated packages.`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìë Let's talk about completion with GPT-3\n",
    "\n",
    "Completions can be used for variety of tasks. It's a simple but powerful text-in and text-out interface. \n",
    "\n",
    "In this snippet, we will be setting up our respective engine for GPT-3 which is `davinci` and also a `prompt` which we want to see completed by GPT-3 model.\n",
    "\n",
    "Upon providing your input as a prompt, the model will generate a text completion that attempts to match whatever context or pattern you gave it. For example, if you a prompt, \"\n",
    "All that glitters is\", it will return the completion \" not gold\" with high probability.\n",
    "\n",
    "üí° Read more about the Completions [here](https://learn.microsoft.com/azure/cognitive-services/openai/how-to/completions?WT.mc_id=AI-MVP-5003464)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customPrompt = \"I climbed a mango tree and picked a \"\n",
    "print(f\"Your input: {customPrompt}\")\n",
    "\n",
    "response = openai.Completion.create(engine=davinci,prompt=customPrompt, max_tokens=100)\n",
    "\n",
    "text = response['choices'][0]['text'].replace('\\n', '').replace(' .', '.').strip()\n",
    "print(f\"GPT-3 Response (Chat): {text}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Sentiment Classifier with Completion API\n",
    "\n",
    "In this example, we provide some sample utterances (past records) to augment the model according to our needs. These examples are a few and hence a good example for few-shot learning within Prompt Engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customPrompt = \"\"\"\n",
    "This is a tweet sentiment classifier. Just provide a sentiment either Positive or Negative. Below is the data\n",
    "\n",
    "---------------------\n",
    "DATA\n",
    "---------------------\n",
    "\n",
    "Tweet: \"I loved the new Batman movie!\"\n",
    "Sentiment: Positive\n",
    "\n",
    "Tweet: \"I hate it when my phone battery dies.\" \n",
    "Sentiment: Negative\n",
    "\n",
    "Tweet: \"My day has been üëç\"\n",
    "Sentiment: Positive\n",
    "\n",
    "Tweet: \"This is the link to the article\"\n",
    "Sentiment: Neutral\n",
    "\n",
    "Tweet: \"I just don't like this movie.\"\n",
    "Sentiment: \n",
    "\"\"\"\n",
    "print(f\"Your input: {customPrompt}\")\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    engine=davinci, prompt=customPrompt, max_tokens=5)\n",
    "text = response['choices'][0]['text'].replace(\n",
    "    '\\n', '').replace(' .', '.').strip()\n",
    "print(f\"GPT-3 Response (Chat): {text}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí¨ ChatGPT & GPT-4\n",
    "\n",
    "Previous models were text-in and text-out, meaning they accepted a prompt string and returned a completion to append to the prompt. However, the ChatGPT and GPT-4 models are conversation-in and message-out. The models expect input formatted in a specific chat-like transcript format, and return a completion that represents a model-written message in the chat. \n",
    "\n",
    "In this case, we're trying to build a flight tracker with the few-shot examples. \n",
    "\n",
    "* ‚úÖ System message, the first one with `\"role\": \"system\"` key is a base for your conversational experience. Try to write as much as you want within it. \n",
    "* ‚úÖ Also, the subsequent messages with are the few shots. `\"role\": \"user\"` defines what user may say whereas `\"role\": \"assistant\"` responds back with the probable answer.\n",
    "\n",
    "You can also use the similar approach to build other use-cases. \n",
    "\n",
    "üí° Learn more about the ChatGPT & GPT-4 models [here](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions&WT.mc_id=AI-MVP-5003464)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customPrompt = \"I want to track flight JF-123 flying from Sydney to Melbourne\"\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=chatgpt,\n",
    "    messages=[\n",
    "        {\"role\": \"system\",\n",
    "            \"content\": \"You are a virtual flight assistant who is responsible for tracking flights. You need either a flight number or source (to) and destination (from) to track any flight. If user does not provide either of this information then you should ask for it. Anything outside of the flights are not a part of your scope and you should just answer with an Unknown intent\"},\n",
    "        {\"role\": \"user\", \"content\": \"Track my flight from Sydney?\"},\n",
    "        {\"role\": \"assistant\",\n",
    "            \"content\": \"Sure! Please provide your destination?\"},\n",
    "        {\"role\": \"user\", \"content\": \"I want to track flight JF-123?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Your flight JF-123 is now departed from Sydney and will be arriving soon in Melbourne at 7 PM\"},\n",
    "        {\"role\": \"user\", \"content\": customPrompt}\n",
    "    ],\n",
    "    temperature=0.9,\n",
    "    max_tokens=150,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`üîî You will be able to look at the multi-turn chat application and that too with voice, very soon in this repo.`\n",
    "\n",
    "## üß† Summarise and Translate \n",
    "\n",
    "While this format was designed specifically for multi-turn conversations, you'll find it can also work well for non-chat scenarios too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textToSummarizeAndTranslate = f\"\"\"\n",
    "As you know, Microsoft‚Äôs AI Builder now supports prebuilt Azure OpenAI models, allowing users to easily integrate powerful AI capabilities into their applications and processes without the need for any coding or data science expertise. In this post, we will explore the benefits and potential use cases of leveraging these prebuilt models with AI Builder.\n",
    "\n",
    "Microsoft‚Äôs AI Builder simplifies the integration of Azure OpenAI models by providing a user-friendly interface for connecting to the OpenAI API. This enables users to access advanced AI capabilities, such as GPT and incorporate them into their applications and workflows with minimal effort. By utilizing prebuilt Azure OpenAI models, users can add powerful AI-driven features to their applications and processes, such as natural language processing, text generation, and more. This can lead to improved efficiency, better decision-making, and more personalized user experiences.\n",
    "\n",
    "Helpful conversational experiences with Power Virtual Agents\n",
    "These latest capabilities of Azure OpenAI in AI Builder are native to Power Automate and Power Apps. This basically means that anything in Power Platform can utilise the capabilities of the GPT models without going to external sources. As a result of that, I created a Power Virutal Agents(PVA) bot using the unified authoring canvas which calls a Power Automate flow to get the answers from Azure OpenAI‚Äòs GPT model.\"\"\"\n",
    "\n",
    "summarizationPrompt = f\"\"\"\n",
    "Summarize the following text for a 140 character tweet and translate it into Urdu.\n",
    "\n",
    "Text: {textToSummarizeAndTranslate}\n",
    "\n",
    "    Summary:\n",
    "\"\"\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=chatgpt,\n",
    "    messages=[\n",
    "        {\"role\": \"system\",\n",
    "            \"content\": \"You're an AI Virtual Assistant responsible for the summarisation and translating the text.\"},\n",
    "        {\"role\": \"user\", \"content\": summarizationPrompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Generate an image with DALL-E 2\n",
    "\n",
    "The image generation API creates an image from a text prompt. It does not edit existing images or create variations. \n",
    "\n",
    "#### üõñ But first, a little housekeeping\n",
    "\n",
    "You may notice a long piece of code and it has a couple of reasons:\n",
    "\n",
    "* ‚ö†Ô∏è The Azure.OpenAI Library does not have a support for DALL-E yet.\n",
    "* ü´∞ In order to show you an image on this Notebook, there's a way which moved Qasim   \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üé® Change the prompt and see the magic! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests\n",
    "%pip install pillow\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Create an image using the image generation API\n",
    "generation_response = openai.Image.create(\n",
    "    prompt='Batman working from home in a rainy season',\n",
    "    size='512x512',\n",
    "    n=2\n",
    ")\n",
    "\n",
    "# Set the directory where we'll store the image\n",
    "image_dir = os.path.join(os.curdir, 'images')\n",
    "# If the directory doesn't exist, create it\n",
    "if not os.path.isdir(image_dir):\n",
    "    os.mkdir(image_dir)\n",
    "\n",
    "# With the directory in place, we can initialize the image path (note that filetype should be png)\n",
    "image_path = os.path.join(image_dir, 'generated_image.png')\n",
    "\n",
    "# Now we can retrieve the generated image\n",
    "# extract image URL from response\n",
    "image_url = generation_response[\"data\"][0][\"url\"]\n",
    "generated_image = requests.get(image_url).content  # download the image\n",
    "with open(image_path, \"wb\") as image_file:\n",
    "    image_file.write(generated_image)\n",
    "\n",
    "# Display the image in the default image viewer\n",
    "display(Image.open(image_path))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
