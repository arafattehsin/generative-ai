{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Generative AI for Developers (C#)\n",
    "`Author: Arafat Tehsin`\n",
    "\n",
    "Well, well, well, looks like we have a language polyglot in the making! And not just any polyglot, but one who's delving into the fascinating world of Azure OpenAI Service. Get ready to unleash your inner coding genius as we take you on a journey from GPT-3 Text Completions to ChatGPT (yes, we're getting chatty here!) and even sprinkle in some DALL-E for good measure. Buckle up, folks, because we're about to turn up the AI heat!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "```\n",
    "Inspired by the great designers at the Microsoft OCTO (Semantic Kernel)\n",
    "```\n",
    "### Reminder: This üìò `Polyglot` notebook needs to be run from VS Code with below pre-requisites. \n",
    "\n",
    "The following software needs to be installed on your computer:\n",
    "\n",
    "* ‚úÖ [Visual Studio Code](https://code.visualstudio.com/Download)\n",
    "* ‚úÖ The latest [.Net 7.0 SDK](https://dotnet.microsoft.com/en-us/download) \n",
    "* ‚úÖ [Polyglot Notebooks for VS Code](https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.dotnet-interactive-vscode?)\n",
    "\n",
    "When the three items above are installed, the code notebooks should be formatted nicely with code blocks that have a little ‚ñ∂Ô∏è (play) button next to them when you hover over the code. The \"Polyglot Notebooks for VS Code\" extension is what lets you run all the code snippets from within VS Code and serves as a little playground for your initial Azure OpenAI learning.\n",
    "\n",
    "Apart from installing software, you will need to have an API key to access the OpenAI models. \n",
    "\n",
    "* ‚úÖ [Azure OpenAI Service](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/quickstart?WT.mc_id=AI-MVP-5003464). Access your API key on Azure Open AI Service with [these instructions](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/reference?WT.mc_id=AI-MVP-5003464).\n",
    "\n",
    "This notebook also requires you to create a deployment of [models](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/models?WT.mc_id=AI-MVP-5003464) üß™. This means that your fresh Azure OpenAI Service won't have any model right now. \n",
    "* ‚úÖ You can create your deployments from [these docs](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal&WT.mc_id=AI-MVP-5003464). The suggestion is to have the deployments similar to their model name. This way OpenAI API would work without any changes in the code:\n",
    "\n",
    "    - `text-davinci-002` - davinci002\n",
    "    - `gpt-35-turbo-16k` - gpt35turbo16k\n",
    "    -  `gpt-4`- gpt40613\n",
    "\n",
    "\n",
    "\n",
    "### üå± Environment Variables\n",
    "\n",
    "Once you get the key and enpoint, you may want to setup from command line or the shiny [Windows Terminal](https://aka.ms/windowsterminal). Again, you can keep any environment variable but this is an example. Mine would be a little different than this too, considering I am working on different Azure regions of Azure OpenAI Service.\n",
    "\n",
    "* `setx AZUREOPENAI_KEY \"your_key_here\"`\n",
    "* `setx AZUREOPENAI_ENDPOINT \"your_enpoint_here\"`\n",
    "\n",
    "Or if you want to use OpenAI\n",
    "\n",
    "* `setx OPENAI_KEY \"your key here\"`\n",
    "\n",
    "#### üìò After you have achieved all the üëÜ prerequisites, open the notebooks in this repo from within Visual Studio Code and you are ready to to go!\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's try this out\n",
    "\n",
    "üëã In the event that you hit \"play\" below on the code block and it asks you to:\n",
    " \n",
    "```\n",
    "Select kernel for <filename>\n",
    "----\n",
    ".NET Interactive üëà\n",
    "Select Another Kernel...\n",
    "----\n",
    "```\n",
    "\n",
    "Choose `.NET Interactive` and you're good to go. That selection lets you magically run the Generative AI notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// üëà you should see a ‚ñ∂Ô∏è (play) button on \n",
    "// the left if you click in this block, \n",
    "// or just hover over this block\n",
    "// CLICK IT! And you should see an output\n",
    "// below this code block.\n",
    "\n",
    "Console.WriteLine(\"Microphone test. Check one. Two. Three.\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a üî• .NET Interactive kernel ready for you to load the Azure OpenAI Service package\n",
    "\n",
    "This will create a client so you don't have to initialise it again. You can read more about the [Azure OpenAI SDK](https://www.nuget.org/packages/Azure.AI.OpenAI/) here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// Getting the latest package released on 15th Dec, 2023 - https://www.nuget.org/packages/Azure.AI.OpenAI\n",
    "#r \"nuget:Azure.AI.OpenAI,*-*\"\n",
    "\n",
    "using Azure;\n",
    "using Azure.AI.OpenAI;\n",
    "using static System.Environment;\n",
    "\n",
    "bool useAzureOpenAI = true;\n",
    "\n",
    "// setting constant for models\n",
    "const string davinci002 = \"davinci-002\";\n",
    "const string gpt35turbo16k = \"gpt-35-turbo-16k\";\n",
    "const string gpt40613 = \"gpt-4-default\";\n",
    "\n",
    "\n",
    "string azureOpenAIKey = Environment.GetEnvironmentVariable(\"AOI_KEY_SWDN\"); // I have got a few \n",
    "string azureOpenAIEndpoint = Environment.GetEnvironmentVariable(\"AOI_ENDPOINT_SWDN\");\n",
    "string openaiKey = Environment.GetEnvironmentVariable(\"OPENAI_KEY\");\n",
    "string cognitiveSearchKey = Environment.GetEnvironmentVariable(\"ENTERPRISEGPT_COGNITIVESEARCH_KEY\");\n",
    "\n",
    "OpenAIClient client = useAzureOpenAI\n",
    "    ? new OpenAIClient(\n",
    "        new Uri(azureOpenAIEndpoint),\n",
    "        new AzureKeyCredential(azureOpenAIKey))\n",
    "    : new OpenAIClient(openaiKey);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you can see a confirmation line above that starts with `Installed Packages ... ‚Ä¢ Azure.AI.OpenAI, 1.0.0-beta.8, ...` then proceed below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìë Let's talk about completion with GPT-3\n",
    "\n",
    "Completions can be used for variety of tasks. It's a simple but powerful text-in and text-out interface. \n",
    "\n",
    "In this snippet, we will be setting up our respective engine for GPT-3 which is `davinci` and also a `prompt` which we want to see completed by GPT-3 model.\n",
    "\n",
    "Upon providing your input as a prompt, the model will generate a text completion that attempts to match whatever context or pattern you gave it. For example, if you a prompt, \"\n",
    "All that glitters is\", it will return the completion \" not gold\" with high probability.\n",
    "\n",
    "üí° Read more about the Completions [here](https://learn.microsoft.com/azure/cognitive-services/openai/how-to/completions?WT.mc_id=AI-MVP-5003464)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string prompt = \"I was going to the airport and I saw\";\n",
    "Console.Write($\"Your input: {prompt}\");\n",
    "\n",
    "CompletionsOptions completionsOptions = new()\n",
    "{\n",
    "    DeploymentName = davinci002, \n",
    "    Prompts = { prompt },\n",
    "    MaxTokens = 40,\n",
    "    Temperature = 0.9F,   \n",
    "};\n",
    "\n",
    "Response<Completions> completionsResponse = client.GetCompletions(completionsOptions);\n",
    "string completion = completionsResponse.Value.Choices[0].Text;\n",
    "Console.Write($\"{completion}\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Sentiment Classifier with Completion API\n",
    "\n",
    "In this example, we provide some sample utterances (past records) to augment the model according to our needs. These examples are a few and hence a good example for few-shot learning within Prompt Engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string prompt = \"\"\"\n",
    "This is a tweet sentiment classifier. Just provide a sentiment either Positive or Negative. Below is the data\n",
    "\n",
    "---------------------\n",
    "DATA\n",
    "---------------------\n",
    "\n",
    "Tweet: \"I loved the new Batman movie!\"\n",
    "Sentiment: Positive\n",
    "\n",
    "Tweet: \"I hate it when my phone battery dies.\" \n",
    "Sentiment: Negative\n",
    "\n",
    "Tweet: \"My day has been üëç\"\n",
    "Sentiment: Positive\n",
    "\n",
    "Tweet: \"This is the link to the article\"\n",
    "Sentiment: Neutral\n",
    "\n",
    "Tweet: \"I just love this cake.\"\n",
    "Sentiment: \n",
    "\"\"\";\n",
    "Console.WriteLine($\"Your input: {prompt}\");\n",
    "\n",
    "CompletionsOptions completionsOptions = new()\n",
    "{\n",
    "    DeploymentName = davinci002, \n",
    "    Prompts = { prompt },\n",
    "    MaxTokens = 10,\n",
    "    Temperature = 0.9F,\n",
    "    StopSequences = { \"\\n\" }\n",
    "};\n",
    "\n",
    "Response<Completions> completionsResponse = client.GetCompletions(completionsOptions);\n",
    "string completion = completionsResponse.Value.Choices[0].Text;\n",
    "Console.Write($\"GPT-3 Response (Chat): {completion.Trim()}\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí¨ ChatGPT & GPT-4\n",
    "\n",
    "Previous models were text-in and text-out, meaning they accepted a prompt string and returned a completion to append to the prompt. However, the ChatGPT and GPT-4 models are conversation-in and message-out. The models expect input formatted in a specific chat-like transcript format, and return a completion that represents a model-written message in the chat. \n",
    "\n",
    "In this case, we're trying to build a flight tracker with the few-shot examples. \n",
    "\n",
    "* ‚úÖ System message, the first one with `ChatRole.System` key is a base for your conversational experience. Try to write as much as you want within it. \n",
    "* ‚úÖ Also, the subsequent messages with are the few shots. `ChatRole.User` defines what user may say whereas `ChatRole.Assisant` responds back with the probable answer.\n",
    "\n",
    "You can also use the similar approach to build other use-cases. \n",
    "\n",
    "üí° Learn more about the ChatGPT & GPT-4 models [here](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions&WT.mc_id=AI-MVP-5003464)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// Enter your query here\n",
    "var prompt = \"I want to track my flight from Bali\";\n",
    "\n",
    "var chatCompletionsOptions = new ChatCompletionsOptions()\n",
    "{\n",
    "    Messages =\n",
    "    {\n",
    "        new ChatRequestSystemMessage(\"You are a virtual flight assistant who is responsible for tracking flights. You need either a flight number or source (to) and destination (from) to track any flight. If user does not provide either of this information then you should ask for it. Anything outside of the flights are not a part of your scope and you should just answer with an Unknown intent.\"),\n",
    "        new ChatRequestUserMessage(\"Track my flight from Sydney?\"),\n",
    "        new ChatRequestAssistantMessage(\"Sure! Please provide your destination?\"),\n",
    "        new ChatRequestUserMessage(\"I want to track flight JF-123?\"),\n",
    "        new ChatRequestAssistantMessage(\"Your flight JF-123 is now departed from Sydney and will be arriving soon in Melbourne at 7 PM\"),\n",
    "        new ChatRequestUserMessage(prompt)\n",
    "    },\n",
    "    MaxTokens = 100,\n",
    "    DeploymentName = gpt35turbo16k\n",
    "};\n",
    "\n",
    "await foreach (StreamingChatCompletionsUpdate chatUpdate in client.GetChatCompletionsStreaming(chatCompletionsOptions))\n",
    "{\n",
    "    if (chatUpdate.Role.HasValue)\n",
    "    {\n",
    "        Console.Write($\"{chatUpdate.Role.Value.ToString().ToUpperInvariant()}: \");\n",
    "    }\n",
    "    if (!string.IsNullOrEmpty(chatUpdate.ContentUpdate))\n",
    "    {\n",
    "        Console.Write(chatUpdate.ContentUpdate);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`üîî You will be able to look at the multi-turn chat application and that too with voice, very soon in this repo.`\n",
    "\n",
    "## üß† Summarise and Translate \n",
    "\n",
    "While this format was designed specifically for multi-turn conversations, you'll find it can also work well for non-chat scenarios too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string textToSummarizeAndTranslate = @\"\n",
    "   As you know, Microsoft‚Äôs AI Builder now supports prebuilt Azure OpenAI models, allowing users to easily integrate powerful AI capabilities into their applications and processes without the need for any coding or data science expertise. In this post, we will explore the benefits and potential use cases of leveraging these prebuilt models with AI Builder.\n",
    "\n",
    "\n",
    "Microsoft‚Äôs AI Builder simplifies the integration of Azure OpenAI models by providing a user-friendly interface for connecting to the OpenAI API. This enables users to access advanced AI capabilities, such as GPT and incorporate them into their applications and workflows with minimal effort. By utilizing prebuilt Azure OpenAI models, users can add powerful AI-driven features to their applications and processes, such as natural language processing, text generation, and more. This can lead to improved efficiency, better decision-making, and more personalized user experiences.\n",
    "\n",
    "Helpful conversational experiences with Power Virtual Agents\n",
    "These latest capabilities of Azure OpenAI in AI Builder are native to Power Automate and Power Apps. This basically means that anything in Power Platform can utilise the capabilities of the GPT models without going to external sources. As a result of that, I created a Power Virutal Agents (PVA) bot using the unified authoring canvas which calls a Power Automate flow to get the answers from Azure OpenAI‚Äòs GPT model.\";\n",
    "\n",
    "string summarizationPrompt = @$\"\n",
    "    Summarize the following text for a 140 character tweet and translate it into Spanish.\n",
    "\n",
    "    Text:\n",
    "    \"\"\"\"\"\"\n",
    "    {textToSummarizeAndTranslate}\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    Summary:\n",
    "\";\n",
    "\n",
    "// Console.Write($\"Input: {summarizationPrompt}\");\n",
    "\n",
    "var chatCompletionsOptions = new ChatCompletionsOptions()\n",
    "{\n",
    "    Messages =\n",
    "    {\n",
    "        new ChatRequestSystemMessage(\"You're an AI Virtual Assistant responsible for the summarisation and translating the text.\"),\n",
    "        new ChatRequestUserMessage(summarizationPrompt)\n",
    "    },\n",
    "    MaxTokens = 200,\n",
    "    DeploymentName = gpt40613\n",
    "};\n",
    "\n",
    "await foreach (StreamingChatCompletionsUpdate chatUpdate in client.GetChatCompletionsStreaming(chatCompletionsOptions))\n",
    "{\n",
    "    if (chatUpdate.Role.HasValue)\n",
    "    {\n",
    "        Console.Write($\"{chatUpdate.Role.Value.ToString().ToUpperInvariant()}: \");\n",
    "    }\n",
    "    if (!string.IsNullOrEmpty(chatUpdate.ContentUpdate))\n",
    "    {\n",
    "        Console.Write(chatUpdate.ContentUpdate);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Generate an image with DALL-E 2\n",
    "\n",
    "The image generation API creates an image from a text prompt. It does not edit existing images or create variations. \n",
    "\n",
    "#### üõñ But first, a little housekeeping\n",
    "\n",
    "You may notice a long piece of code and it has a couple of reasons:\n",
    "\n",
    "* ‚ö†Ô∏è The Azure.OpenAI SDK does not have a support for DALL-E yet.\n",
    "* ü´∞ In order to show you an image on this Notebook, there's a way which moved Qasim   \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üé® Change the prompt and see the magic! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: SkiaSharp, 2.88.3\"\n",
    "\n",
    "#!import Utilities.cs\n",
    "\n",
    "Response<ImageGenerations> imageGenerations = await client.GetImageGenerationsAsync(\n",
    "    new ImageGenerationOptions()\n",
    "    {\n",
    "        Prompt = \"People carrying umbrella on a hot summer day\",\n",
    "        Size = ImageSize.Size1024x1024,\n",
    "        DeploymentName = \"dall-e-3\"\n",
    "    });\n",
    "\n",
    "// Image Generations responses provide URLs you can use to retrieve requested images\n",
    "Uri url = imageGenerations.Value.Data[0].Url;\n",
    "    \n",
    "await Utilities.ShowImage(url.ToString(), 512, 512);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè¢ ChatGPT for your Enterprise with Azure OpenAI on your data\n",
    "\n",
    "Azure OpenAI on your data is a feature that allows you to use OpenAI‚Äôs powerful language models (like GPT-35-Turbo or GPT-4) to generate responses based on your own data. This is done through a REST API or a web-based interface in Azure OpenAI Studio.\n",
    "\n",
    "Think of it like this: You have a database (your box of toys), and you want to find specific information (your favorite toy). Azure OpenAI on your data (your super smart friend) helps you find that information quickly and efficiently.\n",
    "\n",
    "It‚Äôs like having a super smart friend who not only knows everything in your database but can also find and tell you exactly what you want to know in seconds! And the best part? You don‚Äôt need to write complex queries or sift through tons of data yourself.\n",
    "\n",
    "Before you start, make sure you have been approved for Azure OpenAI access and have an Azure OpenAI Service resource with either the gpt-35-turbo or the gpt-4 models deployed. Happy coding! üòä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "AzureCognitiveSearchChatExtensionConfiguration contosoExtensionConfig = new()\n",
    "{\n",
    "    SearchEndpoint = new Uri(\"https://your-contoso-search-resource.search.windows.net\"),\n",
    "    Authentication = new OnYourDataApiKeyAuthenticationOptions(\"<your Cognitive Search resource API key>\"),\n",
    "    IndexName = \"your-index-name\"\n",
    "};\n",
    "\n",
    "ChatCompletionsOptions chatCompletionsOptions = new()\n",
    "{\n",
    "    DeploymentName = \"gpt-35-turbo-0613\",\n",
    "    Messages =\n",
    "    {\n",
    "        new ChatRequestSystemMessage(\n",
    "            \"You are a helpful assistant that answers questions about the Contoso product database.\"),\n",
    "        new ChatRequestUserMessage(\"What are the best-selling Contoso products this month?\")\n",
    "    },\n",
    "\n",
    "    // The addition of AzureChatExtensionsOptions enables the use of Azure OpenAI capabilities that add to\n",
    "    // the behavior of Chat Completions, here the \"using your own data\" feature to supplement the context\n",
    "    // with information from an Azure Cognitive Search resource with documents that have been indexed.\n",
    "    AzureExtensionsOptions = new AzureChatExtensionsOptions()\n",
    "    {\n",
    "        Extensions = { contosoExtensionConfig }\n",
    "    }\n",
    "};\n",
    "\n",
    "Response<ChatCompletions> response = await client.GetChatCompletionsAsync(chatCompletionsOptions);\n",
    "ChatResponseMessage message = response.Value.Choices[0].Message;\n",
    "\n",
    "// The final, data-informed response still appears in the ChatMessages as usual\n",
    "Console.WriteLine($\"{message.Role}: {message.Content}\");\n",
    "\n",
    "// Responses that used extensions will also have Context information that includes special Tool messages\n",
    "// to explain extension activity and provide supplemental information like citations.\n",
    "Console.WriteLine($\"Citations and other information:\");\n",
    "\n",
    "foreach (ChatResponseMessage contextMessage in message.AzureExtensionsContext.Messages)\n",
    "{\n",
    "    // Note: citations and other extension payloads from the \"tool\" role are often encoded JSON documents\n",
    "    // and need to be parsed as such; that step is omitted here for brevity.\n",
    "    Console.WriteLine($\"{contextMessage.Role}: {contextMessage.Content}\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° Function Calling (Coming soon)\n",
    "\n",
    "When you code, sometimes you need to do tasks that are quite common and have been done by many others before, like sorting a list of numbers, finding the current date and time or even complex tasks like making a network request to fetch some data from the internet. Instead of writing all the code for these tasks yourself, you can use pre-written code in the form of functions that come with programming languages or are available in libraries.\n",
    "\n",
    "These functions are like little machines: you give them some input, they do something with that input and then they give you back some output. For example, a function to calculate the square of a number would take a number as input, multiply it by itself and then give you the result.\n",
    "\n",
    "OpenAI‚Äôs function calling is similar. OpenAI has defined a set of functions that the AI can call to perform specific tasks. These tasks could be anything from searching the web to generating an image based on a description. When the AI ‚Äúcalls‚Äù one of these functions, it provides the necessary input and then receives the output once the function has completed its task.\n",
    "\n",
    "Just like when you‚Äôre coding, these functions help the AI to perform tasks more efficiently and effectively, without needing to figure out how to do everything from scratch.\n",
    "\n",
    "### ‚úàÔ∏è Optimising the weather operations \n",
    "\n",
    "In our previous example, we saw that how we shaped up the prompts to get the respective responses while enforcing the required values in our flight tracker. In the below example, we will utilise the function calling capability to optimise our operations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// Coming soon."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
